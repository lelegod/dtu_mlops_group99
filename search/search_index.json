{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Tennis Point Predictor","text":"<p>Welcome to the documentation for Project 99 \u2014 a machine learning application that predicts the outcome of individual tennis points.</p>"},{"location":"#overview","title":"Overview","text":"<p>This project uses an XGBoost gradient boosting model to predict the probability that the server wins a given point in a professional tennis match. Instead of predicting entire match outcomes, the model focuses on point-by-point dynamics of the game.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code># Install dependencies\npip install -r requirements.txt\npip install -e .\n\n# Train the model\npython src/project99/train.py\n\n# Start the API server\nuvicorn project99.api:app --reload\n</code></pre>"},{"location":"#project-structure","title":"Project Structure","text":"<pre><code>dtu_mlops_group99/\n\u251c\u2500\u2500 src/project99/          # Main source code\n\u2502   \u251c\u2500\u2500 api.py              # FastAPI backend\n\u2502   \u251c\u2500\u2500 frontend.py         # Streamlit frontend\n\u2502   \u251c\u2500\u2500 train.py            # Model training script\n\u2502   \u251c\u2500\u2500 data.py             # Data processing pipeline\n\u2502   \u251c\u2500\u2500 model.py            # Model definition\n\u2502   \u251c\u2500\u2500 preprocess.py       # Feature preprocessing\n\u2502   \u2514\u2500\u2500 evaluate.py         # Model evaluation script\n\u251c\u2500\u2500 configs/                # Hydra configuration files\n\u251c\u2500\u2500 data/                   # Raw and processed data\n\u251c\u2500\u2500 dockerfiles/            # Docker configurations\n\u251c\u2500\u2500 tests/                  # Unit and integration tests\n\u2514\u2500\u2500 cloudbuild.yaml         # CI/CD pipeline definition\n</code></pre>"},{"location":"#data-source","title":"Data Source","text":"<p>The project uses Jeff Sackmann's publicly available tennis point-by-point datasets from professional ATP and Grand Slam matches.</p>"},{"location":"#model","title":"Model","text":"<p>The XGBoost classifier is trained with:</p> <ul> <li>500 estimators with learning rate 0.05</li> <li>Max depth 6 for balanced complexity</li> <li>Log loss objective for calibrated probabilities</li> <li>Early stopping to prevent overfitting</li> </ul>"},{"location":"#deployment","title":"Deployment","text":"<p>The application is deployed on Google Cloud Platform:</p> <ul> <li>Model Training: Vertex AI Custom Jobs</li> <li>Model Serving: Vertex AI Endpoints</li> <li>Frontend: Cloud Run (Streamlit)</li> <li>CI/CD: Cloud Build</li> </ul>"},{"location":"api/","title":"API Reference","text":"<p>This page documents the API of the project99 package.</p>"},{"location":"api/#data-processing","title":"Data Processing","text":""},{"location":"api/#tennisdataprocessor","title":"TennisDataProcessor","text":""},{"location":"api/#project99.data.TennisDataProcessor","title":"project99.data.TennisDataProcessor","text":"<p>Processes raw tennis match and point data into ML-ready features.</p> <p>Loads tournament CSV files, engineers features (lagged stats, server/receiver view), and outputs train/test splits.</p> <p>Parameters:</p> Name Type Description Default <code>data_path</code> <code>Path</code> <p>Directory containing -matches.csv and -points.csv files.</p> required"},{"location":"api/#tennis_data","title":"tennis_data","text":""},{"location":"api/#project99.data.tennis_data","title":"project99.data.tennis_data","text":"<pre><code>tennis_data(\n    data_type: str = \"torch\",\n) -&gt; (\n    tuple[TensorDataset, TensorDataset]\n    | tuple[\n        tuple[np.ndarray, np.ndarray],\n        tuple[np.ndarray, np.ndarray],\n    ]\n)\n</code></pre> <p>Load processed tennis data for training.</p> <p>Parameters:</p> Name Type Description Default <code>data_type</code> <code>str</code> <p>Return format - 'torch' for TensorDataset, 'numpy' for arrays.</p> <code>'torch'</code> <p>Returns:</p> Type Description <code>tuple[TensorDataset, TensorDataset] | tuple[tuple[ndarray, ndarray], tuple[ndarray, ndarray]]</code> <p>Train and test datasets as tuple. Format depends on data_type.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If processed data files don't exist.</p> <code>ValueError</code> <p>If data_type is not 'torch' or 'numpy'.</p>"},{"location":"api/#model","title":"Model","text":""},{"location":"api/#model_1","title":"model","text":""},{"location":"api/#project99.model.model","title":"project99.model.model","text":"<pre><code>model(cfg: DictConfig) -&gt; xgb.XGBClassifier\n</code></pre> <p>Create an XGBoost classifier from a Hydra configuration.</p> <p>Initializes an XGBClassifier with hyperparameters specified in the config file.</p> <p>Parameters:</p> Name Type Description Default <code>cfg</code> <code>DictConfig</code> <p>Hydra DictConfig containing model parameters under <code>model.params</code>. Expected keys: max_depth, learning_rate, n_estimators, objective, eval_metric.</p> required <p>Returns:</p> Type Description <code>XGBClassifier</code> <p>Configured XGBClassifier instance ready for training.</p>"},{"location":"api/#training","title":"Training","text":""},{"location":"api/#train","title":"train","text":""},{"location":"api/#project99.train.train","title":"project99.train.train","text":"<pre><code>train(cfg: DictConfig)\n</code></pre> <p>Train an XGBoost model and save to local and GCS.</p> <p>Loads data, trains model with config params, logs metrics to W&amp;B, and saves artifacts.</p> <p>Parameters:</p> Name Type Description Default <code>cfg</code> <code>DictConfig</code> <p>Hydra config with data and model parameters.</p> required"},{"location":"api/#upload_to_gcs","title":"upload_to_gcs","text":""},{"location":"api/#project99.train.upload_to_gcs","title":"project99.train.upload_to_gcs","text":"<pre><code>upload_to_gcs(local_path: str, gcs_path: str)\n</code></pre> <p>Upload a file to Google Cloud Storage.</p> <p>Parameters:</p> Name Type Description Default <code>local_path</code> <code>str</code> <p>Local file path to upload.</p> required <code>gcs_path</code> <code>str</code> <p>GCS destination path (gs://bucket/path/to/file).</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If upload fails.</p>"},{"location":"api/#evaluation","title":"Evaluation","text":""},{"location":"api/#evaluate","title":"evaluate","text":""},{"location":"api/#project99.evaluate.evaluate","title":"project99.evaluate.evaluate","text":"<pre><code>evaluate(model_checkpoint: str | None = None) -&gt; None\n</code></pre> <p>Evaluate a trained XGBoost model on the test set.</p> <p>Loads model from checkpoint and computes metrics: log loss, Brier score, AUC, accuracy.</p> <p>Parameters:</p> Name Type Description Default <code>model_checkpoint</code> <code>str | None</code> <p>Path to model file. Defaults to AIP_MODEL_DIR env var or 'models/xgboost_model.json'.</p> <code>None</code>"},{"location":"api/#preprocessing","title":"Preprocessing","text":""},{"location":"api/#input_preprocessing","title":"input_preprocessing","text":""},{"location":"api/#project99.preprocess.input_preprocessing","title":"project99.preprocess.input_preprocessing","text":"<pre><code>input_preprocessing(raw_point: dict) -&gt; np.ndarray\n</code></pre> <p>Transform raw point data into model features.</p> <p>Converts player-centric input (P1/P2) to server/receiver perspective.</p> <p>Parameters:</p> Name Type Description Default <code>raw_point</code> <code>dict</code> <p>Dictionary with keys: SetNo, GameNo, PointNumber, PointServer, ServeIndicator, P1GamesWon, P1SetsWon, P1Score, P1PointsWon, P1Momentum, P2GamesWon, P2SetsWon, P2Score, P2PointsWon, P2Momentum.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Feature array of shape (1, 20) ready for model prediction.</p>"},{"location":"api/#map_score","title":"map_score","text":""},{"location":"api/#project99.preprocess.map_score","title":"project99.preprocess.map_score","text":"<pre><code>map_score(score: str | int) -&gt; int | float\n</code></pre> <p>Convert tennis score to numeric value.</p> <p>Maps standard tennis scores (\"0\", \"15\", \"30\", \"40\", \"AD\") to integers 0-4. For tiebreak scores, returns the integer value directly.</p> <p>Parameters:</p> Name Type Description Default <code>score</code> <code>str | int</code> <p>Tennis score as string or integer.</p> required <p>Returns:</p> Type Description <code>int | float</code> <p>Numeric score value (0-4 for regular games, or higher int for tiebreaks).</p> <code>int | float</code> <p>Returns np.nan if invalid.</p>"},{"location":"api/#rest-api-endpoints","title":"REST API Endpoints","text":""},{"location":"api/#post-predict","title":"POST /predict","text":""},{"location":"api/#project99.api.predict","title":"project99.api.predict","text":"<pre><code>predict(request: VertexRequest)\n</code></pre> <p>Predict tennis point outcomes.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>VertexRequest</code> <p>VertexRequest containing list of point instances.</p> required <p>Returns:</p> Type Description <p>VertexResponse with predictions and probabilities.</p> <p>Raises:</p> Type Description <code>HTTPException</code> <p>503 if model not loaded, 400 if prediction fails.</p>"},{"location":"api/#get-health","title":"GET /health","text":""},{"location":"api/#project99.api.health_check","title":"project99.api.health_check","text":"<pre><code>health_check()\n</code></pre> <p>Check API health status.</p> <p>Returns:</p> Type Description <p>HealthResponse with status, model_loaded flag, and model_path.</p>"},{"location":"api/#get-modelinfo","title":"GET /model/info","text":""},{"location":"api/#project99.api.model_info","title":"project99.api.model_info","text":"<pre><code>model_info()\n</code></pre> <p>Get information about the loaded model.</p> <p>Returns:</p> Type Description <p>ModelInfoResponse with model type, feature count, and feature names.</p> <p>Raises:</p> Type Description <code>HTTPException</code> <p>503 if model not loaded.</p>"},{"location":"api/#post-predictbatch","title":"POST /predict/batch","text":""},{"location":"api/#project99.api.predict_batch","title":"project99.api.predict_batch  <code>async</code>","text":"<pre><code>predict_batch(file: UploadFile = File(...))\n</code></pre> <p>Batch predict from uploaded CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>UploadFile</code> <p>CSV file with required point columns.</p> <code>File(...)</code> <p>Returns:</p> Type Description <p>BatchPredictionResponse with total count and CSV with predictions.</p> <p>Raises:</p> Type Description <code>HTTPException</code> <p>503 if model not loaded, 400 if file invalid.</p>"}]}